{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NFP-Pix2PixHD.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dvschultz/ai/blob/master/NFP_Pix2PixHD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXoBaXRDKuMV",
        "colab_type": "text"
      },
      "source": [
        "#Next Frame Prediction using Pix2PixHD\n",
        "\n",
        "By Derrick Schultz\n",
        "\n",
        "Forked repo and tutorial based on [JC Testud’s excellent repo and Medium](https://medium.com/@jctestud/video-generation-with-pix2pix-aed5b1b69f57) article."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfOexYWJX3Pt",
        "colab_type": "text"
      },
      "source": [
        "## Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K--AsrIzpH58",
        "colab_type": "code",
        "outputId": "11dd234b-36db-45ba-d495-0bbd22f84de0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUvLbCJtLqaV",
        "colab_type": "text"
      },
      "source": [
        "## Install libraries and dependencies\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3dczlxhXwe6",
        "colab_type": "text"
      },
      "source": [
        "### Run this cell if you’ve yet to install Pix2PixHD in your Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQbRsmWdvjUo",
        "colab_type": "code",
        "outputId": "5c13ff37-6ebf-40b1-9371-5bb3fca428b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd /content/drive/My\\ Drive\n",
        "!mkdir nfp-colab\n",
        "%cd nfp-colab\n",
        "!git clone -b video https://github.com/dvschultz/pix2pixHD.git\n",
        "!pip install dominate\n",
        "%cd pix2pixHD/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yDOMtTH42xl",
        "colab_type": "text"
      },
      "source": [
        "### Run this cell if you’ve already installed Pix2PixHD in Google Drive before"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V94ah70BxPUn",
        "colab_type": "code",
        "outputId": "e37340c8-c78f-4ea7-8e5e-7ab26d55420f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "%cd /content/drive/My\\ Drive/nfp-colab/pix2pixHD/\n",
        "# !git pull\n",
        "!pip install dominate\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/nfp-colab/pix2pixHD\n",
            "Collecting dominate\n",
            "  Downloading https://files.pythonhosted.org/packages/4f/e6/794a119963b7cfe4bd41177c8f9d4195fe901652f04189fbd2edf513c7b2/dominate-2.5.1-py2.py3-none-any.whl\n",
            "Installing collected packages: dominate\n",
            "Successfully installed dominate-2.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzLGf05WXMFV",
        "colab_type": "text"
      },
      "source": [
        "## Extract frames from video\n",
        "\n",
        "Upload a video to either Colab or Google Drive. I’d recommend Colab for speed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWRL2ty6N9LD",
        "colab_type": "code",
        "outputId": "aaec6fcf-148d-426b-cf42-7112fdd789ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "!python extract_frames.py -video /content/glitch-circle-white-720.mov -name glitch-circle-white_dataset -p2pdir . -width 1280 -height 736"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "creating the dataset structure\n",
            "ffmpeg -v 16 -i /content/glitch-circle-white-720.mov -q:v 2 -vf \"scale=iw*736/ih:736, crop=1280:736\" /content/drive/My Drive/nfp-colab/pix2pixHD/datasets/glitch-circle-white_dataset/train_frames/frame-%06d.jpg -hide_banner\n",
            "extracting the frames\n",
            "\u001b[1;35m[NULL @ 0x5565df82d800] \u001b[0m\u001b[1;31mUnable to find a suitable output format for '/content/drive/My'\n",
            "\u001b[0m\u001b[1;31m/content/drive/My: Invalid argument\n",
            "\u001b[0m"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qL9BZkBA_QRR",
        "colab_type": "text"
      },
      "source": [
        "## Train your model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4X7qahzMX05u",
        "colab_type": "text"
      },
      "source": [
        "### Initial training\n",
        "\n",
        "Note: if you have a large dataset, this may timeout initially (`ValueError: __len__() should return >= 0`). Give it a minute or two and run it again."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzHBGVnUKEzE",
        "colab_type": "code",
        "outputId": "3eb5e415-8da3-448d-f9ad-1fdfede3b7ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python train_video.py --name twelve-white --dataroot ./datasets/twelve-white/ --save_epoch_freq 1 #--continue_train"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------ Options -------------\n",
            "batchSize: 1\n",
            "beta1: 0.5\n",
            "checkpoints_dir: ./checkpoints\n",
            "continue_train: False\n",
            "data_type: 32\n",
            "dataroot: ./datasets/twelve-white/\n",
            "debug: False\n",
            "display_freq: 100\n",
            "display_winsize: 512\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "fps: 24.0\n",
            "gpu_ids: [0]\n",
            "heat_seeking_lvl: 0\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: True\n",
            "label_feat: False\n",
            "label_nc: 35\n",
            "lambda_feat: 10.0\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "load_pretrain: \n",
            "local_rank: 0\n",
            "lr: 0.0002\n",
            "max_dataset_size: inf\n",
            "model: pix2pixHD\n",
            "nThreads: 2\n",
            "n_blocks_global: 9\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 4\n",
            "n_layers_D: 3\n",
            "n_local_enhancers: 1\n",
            "name: twelve-white\n",
            "ndf: 64\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter: 100\n",
            "niter_decay: 100\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_ganFeat_loss: False\n",
            "no_html: False\n",
            "no_instance: False\n",
            "no_lsgan: False\n",
            "no_vgg_loss: False\n",
            "norm: instance\n",
            "num_D: 2\n",
            "output_nc: 3\n",
            "phase: train\n",
            "pool_size: 0\n",
            "print_freq: 100\n",
            "pstart: 1\n",
            "pstop: 1\n",
            "resize_or_crop: scale_width\n",
            "save_epoch_freq: 1\n",
            "save_latest_freq: 1000\n",
            "scheduled_sampling: False\n",
            "serial_batches: False\n",
            "ss_recursion_prob: 0.2\n",
            "start_from: video\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "verbose: False\n",
            "video_mode: False\n",
            "which_epoch: latest\n",
            "zoom_lvl: 0\n",
            "-------------- End ----------------\n",
            "CustomDatasetDataLoader\n",
            "dataset [FrameDataset] was created\n",
            "FrameDataset initialized from: ./datasets/twelve-white/train_frames\n",
            "contains 0 frames, -1 consecutive pairs\n",
            "Traceback (most recent call last):\n",
            "  File \"train_video.py\", line 73, in <module>\n",
            "    data_loader = CreateDataLoader(opt) #this will look for a \"frame dataset\" at the location you specified\n",
            "  File \"/content/drive/My Drive/nfp-colab/pix2pixHD/data/data_loader.py\", line 6, in CreateDataLoader\n",
            "    data_loader.initialize(opt)\n",
            "  File \"/content/drive/My Drive/nfp-colab/pix2pixHD/data/custom_dataset_data_loader.py\", line 30, in initialize\n",
            "    num_workers=int(opt.nThreads))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 213, in __init__\n",
            "    sampler = RandomSampler(dataset)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/sampler.py\", line 92, in __init__\n",
            "    if not isinstance(self.num_samples, int) or self.num_samples <= 0:\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/sampler.py\", line 100, in num_samples\n",
            "    return len(self.data_source)\n",
            "ValueError: __len__() should return >= 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GDg3CeW_1TD",
        "colab_type": "text"
      },
      "source": [
        "### Continue Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5q3dE9S_5eg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python train_video.py --name twelve-white --dataroot ./datasets/twelve-white/ --save_epoch_freq 1 --continue_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jly_3OyBoGg2",
        "colab_type": "text"
      },
      "source": [
        "#Generating Videos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INVUtG-pt_F6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python generate_video.py --name fuck-mask --dataroot ./datasets/fuck-mask/ --fps 60 --how_many 600 --which_epoch latest --start_from ./datasets/fuck-mask/train_frames/frame-000060.jpg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiaLMDmdDG3t",
        "colab_type": "code",
        "outputId": "2191c96c-03fa-48e1-8013-ab130e6df9e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "import os\n",
        "\n",
        "def processFolder(folder, epoch = 10, frameCount = 240, skipCount = 1):\n",
        "  files = os.listdir(folder)\n",
        "\n",
        "  count = 0\n",
        "  for f in files:\n",
        "    \n",
        "    if (count % skipCount == 0):\n",
        "      print(f)\n",
        "      if epoch == 'latest':\n",
        "        command = 'python generate_video.py --name glitch_white_circle --dataroot ./datasets/glitch-circle-white_dataset/ --fps 60 --how_many %i --which_epoch latest --start_from %s/%s' % ( frameCount, folder, f)\n",
        "      else:\n",
        "        command = 'python generate_video.py --name glitch_white_circle --dataroot ./datasets/glitch-circle-white_dataset/ --fps 24 --how_many %i --which_epoch %i --start_from %s/%s' % ( frameCount, epoch, folder, f)\n",
        "      os.system(command)\n",
        "    count += 1\n",
        "\n",
        "processFolder('./datasets/fuck-white/train_frames',1,600,3050)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "frame-018504.jpg\n",
            "frame-015525.jpg\n",
            "frame-012746.jpg\n",
            "frame-009603.jpg\n",
            "frame-006972.jpg\n",
            "frame-004082.jpg\n",
            "frame-001186.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5xWj44noo_E",
        "colab_type": "code",
        "outputId": "8532973f-d55f-45cc-abbd-b61a850ab18e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!git pull"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jofBBzcnpu9V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}